-    // Another important optimisation: lengths greater than 48 are rare, so start with copy16
-    // Only fall back to memcopy when the length exceeds 48; copy16 yields better performance.
-    // The cached values below keep hot data local because they stay constant inside the loop
-    // and their values come from seqState, which is provided by the caller.
-    // Reading them directly from seqState would thrash caches and degrade performance.
-    // The three lines above pipeline the loads: fetching data takes time and using it immediately
-    // can stall execution, so we fetch it early to overlap the latency.
-    // Doing other work while the data loads prevents those stalls.
-        // Prefetch state so the next iteration already has these values ready.
-    // The hashLong and hashSmall references in this function
-        // Prefetch instructions
-        // Adapted from a large routine in the original code; introducing loop_mode breaks it into smaller pieces.
-        // Branch prediction optimisation
-            // The original code repeatedly accessed two large tables, causing many cache misses; moving unnecessary branches earlier and ending with a goto saves time.
-    // This section is also ported from the later part of the upstream code.
-    // Hook function
-        // Automatically size hashlog and chainlog according to the L1D cache.
